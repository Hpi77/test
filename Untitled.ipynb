{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c5d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/23 19:15:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num: integer (nullable = true)\n",
      " |-- X: integer (nullable = true)\n",
      " |-- Y: integer (nullable = true)\n",
      " |-- DC: double (nullable = true)\n",
      " |-- ISI: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- num: integer (nullable = true)\n",
      " |-- X: integer (nullable = true)\n",
      " |-- Y: integer (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- FFMC: double (nullable = true)\n",
      " |-- DMC: double (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- RH: integer (nullable = true)\n",
      " |-- wind: double (nullable = true)\n",
      " |-- rain: double (nullable = true)\n",
      " |-- area: double (nullable = true)\n",
      " |-- passenger: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, isnull, when, count\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, StringIndexer\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# 创建Spark会话\n",
    "spark = SparkSession.builder.appName(\"ForestFirePrediction\").getOrCreate()\n",
    "\n",
    "# 读取CSV文件\n",
    "df1 = spark.read.csv('weather.csv', header=True, inferSchema=True)\n",
    "df2 = spark.read.csv('fires.csv', header=True, inferSchema=True)\n",
    "\n",
    "# 打印数据类型和缺失值统计\n",
    "df1.printSchema()\n",
    "df2.printSchema()\n",
    "\n",
    "# 合并数据集\n",
    "df3 = df1.join(df2, on=['X', 'Y', 'num', 'country'], how='outer')\n",
    "\n",
    "# 按国家统计缺失行数\n",
    "missing_ratio_per_country = df3.select('country').withColumn('missing_count', count(when(isnull(col('country')), 1))).groupBy('country').count().orderBy('count', ascending=False)\n",
    "missing_ratio_per_country.show()\n",
    "\n",
    "# 将国家和月份的字符串值转换为数字\n",
    "df3 = df3.replace(['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'], list(range(1, 13)), 'month')\n",
    "df3 = df3.replace(['mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun'], list(range(1, 8)), 'day')\n",
    "df3 = df3.replace(['Portugal', 'Brazil'], [1, 2], 'country')\n",
    "\n",
    "# 填补缺失值\n",
    "df3 = df3.fillna(df3.agg(*[when(isnull(col(c)), col(c).median()).otherwise(col(c)).alias(c) for c in df3.columns]))\n",
    "\n",
    "# 删除巴西的数据\n",
    "df3 = df3.filter(df3['country'] != 2)\n",
    "\n",
    "# 删除不需要的列\n",
    "df5 = df3.drop('num', 'country', 'passenger')\n",
    "\n",
    "# 转换为pandas数据框以进行可视化\n",
    "df5_pd = df5.toPandas()\n",
    "\n",
    "# 绘制缺失值柱状图\n",
    "missing_values = df5_pd.isnull().sum()\n",
    "plt.figure(figsize=(10, 6))\n",
    "missing_values.plot(kind='bar')\n",
    "plt.title('Missing Values in Each Column')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# 绘制密度图\n",
    "sns.kdeplot(data=df5_pd['area'], fill=True)\n",
    "plt.show()\n",
    "\n",
    "# 绘制月度记录数\n",
    "monthly_counts = df5_pd.groupby('month')['area'].count().reset_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(monthly_counts['month'], monthly_counts['area'], color='skyblue')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Records')\n",
    "plt.title('Relationship Between the Number of Area Records and Month')\n",
    "plt.show()\n",
    "\n",
    "# 数据准备\n",
    "feature_columns = [c for c in df5.columns if c not in ['area']]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "df5 = assembler.transform(df5)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "scalerModel = scaler.fit(df5)\n",
    "df5 = scalerModel.transform(df5)\n",
    "\n",
    "# 划分数据集\n",
    "(train_data, test_data) = df5.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 定义模型\n",
    "lr = LinearRegression(featuresCol='scaledFeatures', labelCol='area')\n",
    "\n",
    "# 网格搜索和交叉验证\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).build()\n",
    "crossval = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=RegressionEvaluator(labelCol=\"area\"), numFolds=5)\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "# 预测和评估\n",
    "predictions = cvModel.transform(test_data)\n",
    "evaluator = RegressionEvaluator(labelCol=\"area\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data = {rmse}\")\n",
    "\n",
    "# 随机森林模型\n",
    "rf = RandomForestRegressor(featuresCol='scaledFeatures', labelCol='area')\n",
    "rfModel = rf.fit(train_data)\n",
    "rf_predictions = rfModel.transform(test_data)\n",
    "rf_rmse = evaluator.evaluate(rf_predictions)\n",
    "print(f\"Random Forest RMSE on test data = {rf_rmse}\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1998bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
